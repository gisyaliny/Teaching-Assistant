n.trees = 5000,
shrinkage = 0.1,
interaction.depth = 3,
cv.folds = 10
)
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'response')
Yhat
library(gbm)
set.seed(123)  # for reproducibility
my_gbm <- gbm(
formula = default ~ .,
data = df_train,
distribution = "bernoulli",  # SSE loss function
n.trees = 5000,
cv.folds = 10
)
default
df_train$default
df_train$default <- ifelse(data_x$default == "yes", 1, 0)
df_train$default
df_train$mydefault <- df_train$default
library(gbm)
df_train$mydefault <- df_train$default
df_train$mydefault <- ifelse(as.character(df_train$mydefault)== "yes", 1, 0)
set.seed(123)  # for reproducibility
my_gbm <- gbm(
formula = mydefault ~ .,
data = df_train,
distribution = "bernoulli",  # SSE loss function
n.trees = 5000,
cv.folds = 10
)
(best <- which.min(my_gbm$cv.error))
library(gbm)
df_train$mydefault <- df_train$default
df_train$mydefault <- ifelse(as.character(df_train$mydefault)== "yes", 1, 0)
set.seed(123)  # for reproducibility
my_gbm <- gbm(
formula = mydefault ~ -default.,
data = df_train,
distribution = "bernoulli",  # SSE loss function
n.trees = 5000,
cv.folds = 10
)
library(gbm)
df_train$mydefault <- df_train$default
df_train$mydefault <- ifelse(as.character(df_train$mydefault)== "yes", 1, 0)
set.seed(123)  # for reproducibility
my_gbm <- gbm(
formula = mydefault ~ .-default,
data = df_train,
distribution = "bernoulli",  # SSE loss function
n.trees = 5000,
cv.folds = 10
)
(best <- which.min(my_gbm$cv.error))
## plot error curve
best.iter <- gbm.perf(my_gbm, method = "cv")
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'response')
Yhat
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'class')
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'link')
Yhat
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'responsive')
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'responsive')
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'response')
Yhat
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'response')
predictions <- as.factor(ifelse(Yhat >0.5, "yes","no"))
caret::confusionMatrix(as.factor(df_test$default), predictions,
positive = "yes",dnn = c("Reference","Prediction"))
roc_tree4 <- roc(as.factor(df_test$default), Yhat)
plot(roc_tree4, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree4)))
roc_tree4 <- roc(as.factor(df_test$default), Yhat)
plot(roc_tree4, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree4)))
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
# Modeling packages
library(rpart)       # direct engine for decision tree application
library(caret)       # meta engine for decision tree application
# Model interpretability packages
library(rpart.plot)  # for plotting decision trees
library(vip)         # for feature importance
library(pdp)         # for feature effects
prob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
observation <- as.factor(c(rep("neg",10),rep("pos",10)))
pi <- seq(0.1,0.9,by = 0.1)
get_spec_and_sens <- function(observation,prob,pi){
Sensitivity <- c()
Specificity <- c()
for(i in pi){
pred <- as.factor(ifelse(prob < i, "neg","pos"))
result  <-  caret::confusionMatrix(observation, pred, positive = "pos")
Sensitivity <- c(Sensitivity,result$byClass[1])
Specificity <- c(Specificity,result$byClass[2])
}
df <- t(as.data.frame(cbind(Sensitivity,Specificity)))
colnames(df) <- pi
return(df)
}
result <- get_spec_and_sens(observation,prob,pi)
result
prob2 <- c(0.55,0.05,0.65,0.15,0.75,0.25,0.85,0.35,0.95,0.45,0,0.6,0.1,0.7,0.2,0.8,0.3,0.9,0.4,1)
result2 <- get_spec_and_sens(observation,prob2,pi)
result2
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult1, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult1),'; Area under the curve [b]:',auc(rocResult2)))
?read.csv
df <- read.csv('credit.csv',stringsAsFactors = TRUE)
str(df)
library(tree)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
df_train <- df[index, ]
df_test  <- df[-index, ]
my_tree <- tree(default~., data=df_train,split = "deviance",control=tree.control(nobs = nrow(df_train),minsize=10, mincut=5))
summary(my_tree)
## Feature Interpretation
plot(my_tree); text(my_tree, pretty=0)
pred_default <- predict(my_tree, newdata=df_test, type="class")
caret::confusionMatrix(as.factor(df_test$default), pred_default,
positive = "yes",dnn = c("Reference","Prediction"))
pred_default_prob <- predict(my_tree, newdata=df_test, type="vector")
roc_tree1 <- roc(as.factor(df_test$default), pred_default_prob[,"yes"])
plot(roc_tree1, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree1)))
set.seed(123)
cv.carseats <- cv.tree(my_tree, FUN=prune.misclass, K=10)
par(mfrow = c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type="b", main="Deviance")
plot(cv.carseats$k, cv.carseats$dev, type="b", main="Complexity Parameter")
pruned_tree <- prune.misclass(my_tree, best=6)
plot(pruned_tree); text(pruned_tree, pretty=0)
pred_default2 <- predict(pruned_tree, newdata=df_test, type="class")
caret::confusionMatrix(as.factor(df_test$default), pred_default2,
positive = "yes",dnn = c("Reference","Prediction"))
pred_default2_prob <- predict(pruned_tree, newdata=df_test, type="vector")
roc_tree2 <- roc(as.factor(df_test$default), pred_default2_prob[,"yes"])
plot(roc_tree2, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree2)))
library(ipred)
bagged_tree <- train(
default ~ .,
data = df_train,
method = "treebag",
trControl = trainControl(method = "cv", number = 10),
nbagg = 200,
control = rpart.control(minsplit = 2, cp = 0)
)
pred_default2 <- predict(bagged_tree, newdata=df_test, type="raw")
caret::confusionMatrix(as.factor(df_test$default), pred_default2,
positive = "yes",dnn = c("Reference","Prediction"))
pred_default3_prob <- predict(bagged_tree, newdata=df_test, type="prob")
roc_tree3 <- roc(as.factor(df_test$default), pred_default3_prob[,"yes"])
plot(roc_tree3, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree3)))
library(ranger)    ## It is internally parallel
# number of features
n_features <- length(setdiff(names(df_train), "default"))
n_features
# train a default random forest model
default_rf <- ranger(
default ~ .,
data = df_train,
mtry = floor(n_features / 3),
respect.unordered.factors = "order",
seed = 123
)
# get OOB RMSE
(default_rmse <- sqrt(default_rf$prediction.error))
# create hyperparameter grid
hyper_grid <- expand.grid(
mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
min.node.size = c(1, 3, 5, 10),
replace = c(TRUE, FALSE),
sample.fraction = c(.5, .63, .8),
rmse = NA
)
# execute full cartesian grid search
for(i in seq_len(nrow(hyper_grid))) {
# fit model for ith hyperparameter combination
fit <- ranger(
formula         = default ~ .,
data            = df_train,
num.trees       = n_features * 10,
mtry            = hyper_grid$mtry[i],
min.node.size   = hyper_grid$min.node.size[i],
replace         = hyper_grid$replace[i],
sample.fraction = hyper_grid$sample.fraction[i],
verbose         = FALSE,
seed            = 123,
respect.unordered.factors = 'order',
)
# export OOB error
hyper_grid$rmse[i] <- sqrt(fit$prediction.error)
}
# assess top 10 models
hyper_grid %>%
arrange(rmse) %>%
mutate(perc_gain = (default_rmse - rmse) / default_rmse * 100) %>%
head(10)
# re-run model with impurity-based variable importance
rf_impurity <- ranger(
formula = default ~ .,
data = df_train,
num.trees = 500,
mtry = 5,
min.node.size = 1,
sample.fraction = .50,
replace = FALSE,
probability  = TRUE,
importance = "impurity",
respect.unordered.factors = "order",
verbose = FALSE,
seed  = 123
)
p1 <- vip::vip(rf_impurity, num_features = 25, bar = FALSE)
p1
pred_default4 <- predict(rf_impurity, df_test)
predictions <- as.factor(ifelse(pred_default4$predictions[,"yes"] >0.5, "yes","no"))
caret::confusionMatrix(as.factor(df_test$default), predictions,
positive = "yes",dnn = c("Reference","Prediction"))
roc_tree2 <- roc(as.factor(df_test$default), pred_default4$predictions[,"yes"])
plot(roc_tree2, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree2)))
library(gbm)
df_train$mydefault <- df_train$default
df_train$mydefault <- ifelse(as.character(df_train$mydefault)== "yes", 1, 0)
set.seed(123)  # for reproducibility
my_gbm <- gbm(
formula = mydefault ~ .-default,
data = df_train,
distribution = "bernoulli",  # SSE loss function
n.trees = 5000,
cv.folds = 10
)
(best <- which.min(my_gbm$cv.error))
## plot error curve
best.iter <- gbm.perf(my_gbm, method = "cv")
Yhat <- predict(my_gbm, newdata = df_test, n.trees = best.iter,type = 'response')
predictions <- as.factor(ifelse(Yhat >0.5, "yes","no"))
caret::confusionMatrix(as.factor(df_test$default), predictions,
positive = "yes",dnn = c("Reference","Prediction"))
roc_tree4 <- roc(as.factor(df_test$default), Yhat)
plot(roc_tree4, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree4)))
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult1, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult1),'; Area under the curve [b]:',auc(rocResult2)))
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
# Modeling packages
library(rpart)       # direct engine for decision tree application
library(caret)       # meta engine for decision tree application
# Model interpretability packages
library(rpart.plot)  # for plotting decision trees
library(vip)         # for feature importance
library(pdp)         # for feature effects
prob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
observation <- as.factor(c(rep("neg",10),rep("pos",10)))
pi <- seq(0.1,0.9,by = 0.1)
get_spec_and_sens <- function(observation,prob,pi){
Sensitivity <- c()
Specificity <- c()
for(i in pi){
pred <- as.factor(ifelse(prob < i, "neg","pos"))
result  <-  caret::confusionMatrix(observation, pred, positive = "pos")
Sensitivity <- c(Sensitivity,result$byClass[1])
Specificity <- c(Specificity,result$byClass[2])
}
df <- t(as.data.frame(cbind(Sensitivity,Specificity)))
colnames(df) <- pi
return(df)
}
result <- get_spec_and_sens(observation,prob,pi)
result
prob2 <- c(0.55,0.05,0.65,0.15,0.75,0.25,0.85,0.35,0.95,0.45,0,0.6,0.1,0.7,0.2,0.8,0.3,0.9,0.4,1)
result2 <- get_spec_and_sens(observation,prob2,pi)
result2
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult1, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult1),'; Area under the curve [b]:',auc(rocResult2)))
knit_with_parameters('G:/UTD_Classes/Teaching-Assistant/2021-Spring/GISC-6323-Machine-Learning-for-Socio-Economic-and-Geo-Referenced-Data/Labs/Lab03/YalinLab03_new.rmd', encoding = 'UTF-8')
unlink('YalinLab03_new_cache', recursive = TRUE)
install.packages("pROC")
install.packages("pROC")
install.packages("pROC")
library(pROC)
library(tree)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
# Modeling packages
library(rpart)       # direct engine for decision tree application
library(caret)       # meta engine for decision tree application
# Model interpretability packages
library(rpart.plot)  # for plotting decision trees
library(vip)         # for feature importance
library(pdp)         # for feature effects
?read.csv
df <- read.csv('credit.csv',stringsAsFactors = TRUE)
str(df)
library(tree)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
my_tree <- tree(default~., data=train,split = "deviance",control=tree.control(nobs = nrow(train),minsize=10, mincut=5))
summary(my_tree)
## Feature Interpretation
plot(my_tree); text(my_tree, pretty=0)
pred_default <- predict(my_tree, newdata=test, type="class")
caret::confusionMatrix(as.factor(test$default), pred_default,
positive = "yes",dnn = c("Reference","Prediction"))
(confMat <- table(test_data$default, pred_default))
(confMat <- table(test$default, pred_default))
caret::confusionMatrix(as.factor(test$default), pred_default,
positive = "yes",dnn = c("Reference","Prediction"))
(confMat <- table(test$default, pred_default))
caret::confusionMatrix(as.factor(test$default), pred_default,
positive = "yes",dnn = c("Reference","Prediction"))
(confMat <- table(test$default, pred_default))
predicted_probability = predict(my_tree, test, type = "prob")[,2]
predicted_probability = predict(my_tree, test, type = "vector")[,2]
pred2 = prediction(predicted_probability, test$default)
?prediction
??prediction
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
library(ROCR)
library(RColorBrewer)
# Modeling packages
library(rpart)       # direct engine for decision tree application
library(caret)       # meta engine for decision tree application
library(rattle)
library(ranger)
library(gbm)
# Model interpretability packages
library(rpart.plot)  # for plotting decision trees
library(vip)         # for feature importance
library(pdp)         # for feature effects
library(ipred)
# library(dplyr)       # for data wrangling
# library(ggplot2)     # for awesome plotting
# library(ROCR)
# library(RColorBrewer)
#
# # Modeling packages
# library(rpart)       # direct engine for decision tree application
# library(caret)       # meta engine for decision tree application
# library(rattle)
# library(ranger)
# library(gbm)
#
# # Model interpretability packages
# library(rpart.plot)  # for plotting decision trees
# library(vip)         # for feature importance
# library(pdp)         # for feature effects
# library(ipred)
pred_default <- predict(my_tree, newdata=test, type="class")
caret::confusionMatrix(as.factor(test$default), pred_default,
positive = "yes",dnn = c("Reference","Prediction"))
(confMat <- table(test$default, pred_default))
predicted_probability = predict(my_tree, test, type = "vector")[,2]
??prediction
pred2 = prediction(predicted_probability, test$default)
(auc_roc = performance(pred2,"acc"))
(auc_roc = performance(pred2,"acc"))
library(e1071); library(ISLR) ;library(gmodels); library(ROCR); library(caret)
##
## Support Vector Classifier
##
RNGversion("3.5.1"); set.seed(1)
x <- matrix(rnorm(20*2), ncol=2)
y <- c(rep(-1,10), rep(1,10))
x[y==1,] <- x[y==1,] + 1
plot(x[,1]~x[,2], col=(3-y), cex=1.5, pch=19)
df <- data.frame(x=x, y=as.factor(y))
help(svm)
help(svm)
svmfit <- svm(y~., data=df, kernel="linear", cost=10, scale=FALSE)
plot(svmfit, df)
svmfit$index           # Observations used as support vectors
summary(svmfit)
svmfit <- svm(y~., data=df, kernel="linear", cost=0.1, scale=FALSE)
plot(svmfit, df)
svmfit$index
summary(svmfit)
## Find best cost parameter
set.seed(1)
tune.out <- tune(svm, y~.,data=df,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
bestmod <- tune.out$best.model
summary(bestmod)
## Set up test data
xtest <- matrix(rnorm(20*2), ncol=2)
ytest <- sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,] <- xtest[ytest==1,] + 1
testdat <- data.frame(x=xtest, y=as.factor(ytest))
ypred <- predict(bestmod, testdat)
table(predict=ypred, truth=testdat$y)
## Define linearly separable training sample by increasing the seperation
x[y==1,] <- x[y==1,]+0.5
plot(x[,1]~x[,2], col=(y+5)/2, cex=1.5, pch=19)
df <- data.frame(x=x, y=as.factor(y))
svmfit <- svm(y~., data=df, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, df)
svmfit=svm(y~., data=df, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit,df)
summary(svmfit)
summary(svmfit)
svmfit <- svm(y~., data=df, kernel="linear", cost=1e5)
summary(svmfit)
summary(svmfit)
svmfit=svm(y~., data=df, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit,df)
##
## Support Vector Machine
##
set.seed(1)
x <- matrix(rnorm(200*2), ncol=2)
x[1:100,] <- x[1:100,]+2
x[101:150,] <- x[101:150,]-2
y <- c(rep(1,150),rep(2,50))
df <- data.frame(x=x, y=as.factor(y))
plot(x[,1]~x[,2], col=y)
train <- sample(1:200, 100)
svmfit <- svm(y~., data=df[train,], kernel="radial",  gamma=1, cost=1)
plot(svmfit, df[train,])
summary(svmfit)
svmfit <- svm(y~., data=df[train,], kernel="radial",gamma=1, cost=1e5)
plot(svmfit,df[train,])
summary(svmfit)
set.seed(1)
tune.out <- tune(svm, y~., data=df[train,], kernel="radial",
ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
summary(tune.out$best.model)
table(true=df[-train,"y"],
pred=predict(tune.out$best.model,newdata=df[-train,]))
plot(perf,...)}
old.par <- par(mfrow=c(1,2))
## Training ROC
svmfit.opt <- svm(y~., data=df[train,], kernel="radial",gamma=2, cost=1, decision.values=T)
fitted <- attributes(predict(svmfit.opt, df[train,], decision.values=TRUE))$decision.values
rocplot(fitted,df[train,"y"], main="Training Data")
# ROC Curves
rocplot <- function(pred, truth, ...){
predob = prediction(pred, truth)
perf = performance(predob, "tpr", "fpr")
plot(perf,...)}
old.par <- par(mfrow=c(1,2))
## Training ROC
svmfit.opt <- svm(y~., data=df[train,], kernel="radial",gamma=2, cost=1, decision.values=T)
fitted <- attributes(predict(svmfit.opt, df[train,], decision.values=TRUE))$decision.values
rocplot(fitted,df[train,"y"], main="Training Data")
svmfit.flex <- svm(y~., data=df[train,], kernel="radial",gamma=50, cost=1, decision.values=T)
fitted <- attributes(predict(svmfit.flex,df[train,],decision.values=T))$decision.values
rocplot(fitted,df[train,"y"], add=T, col="red")
## Test ROC
fitted <- attributes(predict(svmfit.opt, df[-train,],decision.values=T))$decision.values
rocplot(fitted,df[-train,"y"], main="Test Data")
fitted <- attributes(predict(svmfit.flex, df[-train,],decision.values=T))$decision.values
rocplot(fitted, df[-train,"y"], add=T, col="red")
par(old.par)
# SVM with Multiple Classes
set.seed(1)
x <- rbind(x, matrix(rnorm(50*2), ncol=2))
y <- c(y, rep(0,50))
x[y==0,2] <- x[y==0,2]+2
df <- data.frame(x=x, y=as.factor(y))
plot(x[,1]~x[,2], col=(y+1))
svmfit <- svm(y~., data=df, kernel="radial", cost=10, gamma=1)
plot(svmfit, df)
##
## Application to Gene Expression Data
##
library(ISLR)
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
df <- data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
## High dimensional data justify linear hyperplanes
out <- svm(y~., data=df, kernel="linear",cost=10)
summary(out)
table(out$fitted, df$y)
df.te <- data.frame(x=Khan$xtest, y=as.factor(Khan$ytest))
pred.te <- predict(out, newdata=df.te)
table(pred.te, df.te$y)
