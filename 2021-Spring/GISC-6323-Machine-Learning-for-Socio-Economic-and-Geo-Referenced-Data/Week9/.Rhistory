predkNN <- predict(knn_fit, default_test, type="prob")
predGLM <- predict(creStep, newdata=default_test, type="response")
hist(predkNN[,"yes"])
hist(predGLM)
delta <- 0.4                  # Set cut-off probability
## Convert probabilities with cut-off to default and no-default
kNNPredDefault <- ifelse(predkNN[,"yes"] <= delta, "no", "yes")
kNNPredDefault <- as.factor(kNNPredDefault)
barchart(kNNPredDefault)
## Evaluate kNN predictions
CrossTable(default_test$default, kNNPredDefault)
caret::confusionMatrix(default_test$default, kNNPredDefault,
positive = "yes",dnn = c("Reference","Prediction"))
?caret::confusionMatrix
## Convert probabilities with cut-off to default and no-default
glmPredDefault <- ifelse(predGLM <= delta, "yes", "no")
glmPredDefault <- as.factor(glmPredDefault)
barchart(glmPredDefault)
## Evaluate kNN predictions
CrossTable(default_test$default, glmPredDefault)
caret::confusionMatrix(default_test$default, glmPredDefault,
positive = "yes",dnn = c("Reference","Prediction"))
## Evaluate ROC curves for kNN
rockNN <- roc(default_test$default, predkNN[,"yes"])
plot(rockNN, main="ROC curve for kNN and GLM predicted probabilities",
col="blue", lwd=2, legacy.axes=TRUE)
legend("bottomright", legend=c("kNN","GLM"), lty=1, col=c("blue","red"))
# compare GLM
rocGLM <- roc(default_test$default, predGLM)
plot(rocGLM, col="red", lwd=2, add=TRUE)
# calculate AUC for Naive Bayes and kNN
auc(rockNN)
auc(rocGLM)
default_test$default
predGLM
Pi <- seq(0,1,by=0.05)
Pi
Pob <- seq(0,1,by=0.05)
Observation <- c(rep("neg",10),rep("pos",10))
Pi <- seq(0.1,0.9,by = 0.1)
Pred <- ifelse(Pob < Pi, "neg","pos")
Pob <- seq(0,1,by=0.05)
Observation <- c(rep("neg",10),rep("pos",10))
Pi <- seq(0.1,0.9,by = 0.1)
Pred <- ifelse(Pob < Pi, "neg","pos")
Pred
Pob <- seq(0,1,by=0.05)
Observation <- c(rep("neg",10),rep("pos",10))
Pi <- seq(0.1,0.9,by = 0.1)
Pred <- ifelse(Pob < Pi, "neg","pos")
rocGLM <- roc(Observation, Pred)
plot(rockNN, main="ROC curve for kNN and GLM predicted probabilities",
col="blue", lwd=2, legacy.axes=TRUE)
legend("bottomright", legend=c("kNN","GLM"), lty=1, col=c("blue","red"))
rocGLM <- roc(Observation, Pob)
rocGLM
plot(rocGLM, col="red", lwd=2, add=TRUE)
rocGLM <- roc(Observation, Pob)
# compare GLM
predGLM
rocGLM <- roc(Observation, Pob)
Pob
Pob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
Observation <- c(rep("neg",10),rep("pos",10))
Pi <- seq(0.1,0.9,by = 0.1)
rocGLM <- roc(Observation, Pob)
plot(rocGLM, col="red", lwd=2, add=TRUE)
rocGLM <- roc(Observation, Pob)
rocGLM
plot(rocGLM, col="red", lwd=2, add=TRUE)
plot(rockNN, main="ROC curve for kNN and GLM predicted probabilities",
col="blue", lwd=2, legacy.axes=TRUE)
predkNN[,"yes"]
plot(rocGLM, col="red", lwd=2, add=TRUE)
rocGLM <- roc(Observation, Pob)
plot(rocGLM, col="red", lwd=2, add=TRUE)
## Evaluate ROC curves for kNN
class(default_test$default)
class(predkNN[,"yes"])
Observation <- as.factor(c(rep("neg",10),rep("pos",10)))
rocGLM <- roc(Observation, Pob)
plot(rocGLM, col="red", lwd=2, add=TRUE)
Observation <- as.factor(c(rep("neg",10),rep("pos",10)))
Observation
Pob
predkNN[,"yes"]
roc <- roc(Observation, Pob)
Pob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
Observation <- as.factor(c(rep("neg",10),rep("pos",10)))
Pi <- seq(0.1,0.9,by = 0.1)
Pred <- ifelse(Pob < Pi, "neg","pos")
rocGLM <- roc(Observation, Pob)
plot(rocGLM, col="red", lwd=2, add=TRUE)
Pob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
Observation <- as.factor(c(rep("neg",10),rep("pos",10)))
Pi <- seq(0.1,0.9,by = 0.1)
Pred <- ifelse(Pob < Pi, "neg","pos")
rocResult <- roc(Observation, Pob)
plot(rocResult)
Pob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
Observation <- as.factor(c(rep("neg",10),rep("pos",10)))
Pi <- seq(0.1,0.9,by = 0.1)
Pred <- ifelse(Pob < Pi, "neg","pos")
rocResult <- roc(Observation, Pob)
plot(rocResult, col="red", lwd=2)
Pred <- ifelse(Pob < 0.1, "neg","pos")
result  <-  caret::confusionMatrix(Observation, Pred, positive = "pos")
Pred <- as.factor(ifelse(Pob < 0.1, "neg","pos"))
result  <-  caret::confusionMatrix(Observation, Pred, positive = "pos")
result
result$mode
result$positive
result$table
result$overall
result$byClass
result$byClass[1]
result$byClass
get_spec_and_sens(observation,prediction){
get_spec_and_sens(observation,prediction){
get_spec_and_sens(observation,prediction){
Pob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
Observation <- as.factor(c(rep("neg",10),rep("pos",10)))
Pi <- seq(0.1,0.9,by = 0.1)
get_spec_and_sens(observation,prediction){
rocResult <- roc(Observation, Pob)
plot(rocResult, col="red", lwd=2)
prob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
observation <- as.factor(c(rep("neg",10),rep("pos",10)))
pi <- seq(0.1,0.9,by = 0.1)
get_spec_and_sens <- function(observation,prob,pi){
Sensitivity <- c()
Specificity <- c()
for(i in Pi){
pred <- as.factor(ifelse(prob < i, "neg","pos"))
result  <-  caret::confusionMatrix(Observation, pred, positive = "pos")
Sensitivity <- c(Sensitivity,result$byClass[1])
Specificity <- c(Specificity,result$byClass[1])
}
return(as.data.frame(cbind(Sensitivity,Specificity)))
}
result <- get_spec_and_sens(observation,prob,pi)
result
prob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
observation <- as.factor(c(rep("neg",10),rep("pos",10)))
pi <- seq(0.1,0.9,by = 0.1)
get_spec_and_sens <- function(observation,prob,pi){
Sensitivity <- c()
Specificity <- c()
for(i in Pi){
pred <- as.factor(ifelse(prob < i, "neg","pos"))
result  <-  caret::confusionMatrix(Observation, pred, positive = "pos")
Sensitivity <- c(Sensitivity,result$byClass[1])
Specificity <- c(Specificity,result$byClass[1])
}
df <- as.data.frame(cbind(Sensitivity,Specificity))
row.names(df) <- pi
return(df)
}
result <- get_spec_and_sens(observation,prob,pi)
result
prob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
observation <- as.factor(c(rep("neg",10),rep("pos",10)))
pi <- seq(0.1,0.9,by = 0.1)
get_spec_and_sens <- function(observation,prob,pi){
Sensitivity <- c()
Specificity <- c()
for(i in Pi){
pred <- as.factor(ifelse(prob < i, "neg","pos"))
result  <-  caret::confusionMatrix(Observation, pred, positive = "pos")
Sensitivity <- c(Sensitivity,result$byClass[1])
Specificity <- c(Specificity,result$byClass[2])
}
df <- as.data.frame(cbind(Sensitivity,Specificity))
row.names(df) <- pi
return(df)
}
result <- get_spec_and_sens(observation,prob,pi)
result
rocResult <- roc(Observation, Pob)
plot(rocResult, col="red", lwd=2)
auc(rocResult)
auc(rocResult)
prob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
observation <- as.factor(c(rep("neg",10),rep("pos",10)))
pi <- seq(0.1,0.9,by = 0.1)
get_spec_and_sens <- function(observation,prob,pi){
Sensitivity <- c()
Specificity <- c()
for(i in Pi){
pred <- as.factor(ifelse(prob < i, "neg","pos"))
result  <-  caret::confusionMatrix(Observation, pred, positive = "pos")
Sensitivity <- c(Sensitivity,result$byClass[1])
Specificity <- c(Specificity,result$byClass[2])
}
df <- t(as.data.frame(cbind(Sensitivity,Specificity)))
colnames(df) <- pi
return(df)
}
result <- get_spec_and_sens(observation,prob,pi)
result
result
rocResult <- roc(Observation, Pob)
plot(rocResult, col="red", lwd=2)
auc(rocResult)
prob <- c(0.55,0.05,0.65,0.15,0.75,0.25,0.85,0.35,0.95,0.45,0,0.6,0.1,0.7,0.2,0.8,0.3,0.9,0.4,1)
result2 <- get_spec_and_sens(observation,prob,pi)
result2
prob <- c(seq(0,0.45,by=0.05),seq(0.55,1,by=0.05))
observation <- as.factor(c(rep("neg",10),rep("pos",10)))
pi <- seq(0.1,0.9,by = 0.1)
get_spec_and_sens <- function(observation,prob,pi){
Sensitivity <- c()
Specificity <- c()
for(i in Pi){
pred <- as.factor(ifelse(prob < i, "neg","pos"))
result  <-  caret::confusionMatrix(Observation, pred, positive = "pos")
Sensitivity <- c(Sensitivity,result$byClass[1])
Specificity <- c(Specificity,result$byClass[2])
}
df <- t(as.data.frame(cbind(Sensitivity,Specificity)))
colnames(df) <- pi
return(df)
}
result <- get_spec_and_sens(observation,prob,pi)
result
prob2 <- c(0.55,0.05,0.65,0.15,0.75,0.25,0.85,0.35,0.95,0.45,0,0.6,0.1,0.7,0.2,0.8,0.3,0.9,0.4,1)
result2 <- get_spec_and_sens(observation,prob2,pi)
result2
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
# auc(rocResult)
auc(rocResult)
paste('a',auc(rocResult))
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult),'Area under the curve [b]:',auc(rocResult2)))
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult),'\nArea under the curve [b]:',auc(rocResult2)))
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult),'\t Area under the curve [b]:',auc(rocResult2)))
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult),'; Area under the curve [b]:',auc(rocResult2)))
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult),'; Area under the curve [b]:',auc(rocResult2)))
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult),'; Area under the curve [b]:',auc(rocResult2)))
rocResult1 <- roc(observation, prob)
rocResult2 <- roc(observation, prob2)
plot(rocResult, col="red", lwd=2)
plot(rocResult2, col="blue", lwd=2, add = TRUE)
legend("bottomright", legend=c("[b]","[a]"), lty=1, col=c("blue","red"))
title(main = paste('Area under the curve [a]:',auc(rocResult),'; Area under the curve [b]:',auc(rocResult2)))
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
# Modeling packages
library(rpart)       # direct engine for decision tree application
library(caret)       # meta engine for decision tree application
# Model interpretability packages
library(rpart.plot)  # for plotting decision trees
library(vip)         # for feature importance
library(pdp)         # for feature effects
df <- read.csv('credit.csv')
df <- read.csv('credit.csv')
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
df <- read.csv('credit.csv')
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
##
## caret cross validation results
##
my_tree <- train(
default ~ .,
data = train,
method = "rpart",
trControl = trainControl(method = "cv", mincut = 5,minsize = 10),
tuneLength = 20
)
df <- read.csv('credit.csv')
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
my_tree <- rpart(
formula = default ~ .,
data    = train,
method  = "anova",
control = list(mincut = 5, minsize = 10)
)
df <- read.csv('credit.csv')
summary(df)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
my_tree <- rpart(
formula = default ~ .,
data    = train,
method  = "anova",
control = list(mincut = 5, minsize = 10)
)
ggplot(my_tree)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
my_tree <- rpart(
formula = default ~ .,
data    = train,
method  = "anova",
control = list(mincut = 5, minsize = 10)
)
plotcp(my_tree)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
my_tree <- rpart(
formula = default ~ .,
data    = train,
method  = "anova",
control = list(mincut = 5, minsize = 10)
)
plotcp(my_tree)
my_tree
train$default
my_tree <- rpart(
formula = default ~ .,
data    = train,
control = list(mincut = 5, minsize = 10)
)
plotcp(my_tree)
abline(v = 11, lty = "dashed")
plotcp(my_tree)
my_tree
ggplot(my_tree)
source('G:/UTD_Classes/Teaching-Assistant/2021-Spring/GISC-6323-Machine-Learning-for-Socio-Economic-and-Geo-Referenced-Data/Week9/CART.R')
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
df <- read.csv('credit.csv')
summary(df)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
my_tree <- rpart(
formula = default ~ .,
data    = train,
control = list(mincut = 5, minsize = 10)
)
plotcp(my_tree)
rpart.plot(my_tree)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
my_tree <- rpart(
formula = default ~ .,
data    = train,
control = list(mincut = 5, minsize = 10)
)
plotcp(my_tree)
rpart.plot(my_tree)
## Feature Interpretation
vip(my_tree, num_features = 10, bar = FALSE)
## Construct partial dependence plots
p1 <- partial(my_tree, pred.var = "checking_balance") %>% autoplot()
class(my_tree)
rpart.rules(my_tree)
rpart.plot(my_tree, type = 3, clip.right.labs = FALSE, branch = .3, under = TRUE)
set.seed(123)  # for reproducibility
index <- createDataPartition(df$default, p = 0.7, list = FALSE)
train <- df[index, ]
test  <- df[-index, ]
my_tree <- rpart(
formula = default ~ .,
data    = train,
control = list(mincut = 5, minsize = 10)
)
pred_default <- predict(my_tree, newdata=test, type="response")
pred_default <- predict(my_tree, newdata=test)
pred_default
pred_default <- predict(my_tree, newdata=test, type="response")
pred_default <- predict(my_tree, newdata=test, type="class")
pred_default
pred_default <- predict(my_tree, newdata=test, type="class")
caret::confusionMatrix(test$default, pred_default,
positive = "yes",dnn = c("Reference","Prediction"))
test$default
pred_default <- predict(my_tree, newdata=test, type="class")
caret::confusionMatrix(as.factor(test$default), pred_default,
positive = "yes",dnn = c("Reference","Prediction"))
roc_tree1 <- roc(as.factor(test$default), pred_default)
predGLM <- predict(creStep, newdata=default_test, type="response")
pred_default_prob <- predict(my_tree, newdata=test, type="prob")
roc_tree1 <- roc(as.factor(test$default), pred_default_prob)
pred_default_prob
roc_tree1 <- roc(as.factor(test$default), pred_default_prob["yes"])
roc_tree1 <- roc(as.factor(test$default), pred_default_prob[,"yes"])
plot(roc_tree1, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree1)))
pred_default_prob <- predict(my_tree, newdata=test, type="prob")
roc_tree1 <- roc(as.factor(test$default), pred_default_prob[,"yes"])
plot(roc_tree1, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree1)))
pred_default_prob <- predict(my_tree, newdata=test, type="prob")
roc_tree1 <- roc(as.factor(test$default), pred_default_prob[,"yes"])
plot(roc_tree1, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree1)))
## Feature Interpretation
vip(my_tree, bar = FALSE)
## Feature Interpretation
vip(my_tree, bar = FALSE)
## Feature Interpretation
vip(my_tree, num_features = 20, bar = FALSE)
## Feature Interpretation
vip(my_tree, num_features = 20, bar = FALSE)
## Feature Interpretation
vip(my_tree, num_features = 30, bar = FALSE)
## Feature Interpretation
vip(my_tree, num_features = 20, bar = FALSE)
pruned_tree <- train(
default ~ .,
data = train,
method = "rpart",
trControl = trainControl(method = "cv", number = 10),
tuneLength = 20
)
pruned_tree <- train(
default ~ .,
data = train,
method = "rpart",
trControl = trainControl(method = "cv", number = 10),
tuneLength = 20
)
ggplot(pruned_tree)
pruned_tree <- train(
default ~ .,
data = train,
method = "rpart",
trControl = trainControl(method = "cv", number = 10),
tuneLength = 20
)
plotcp(pruned_tree)
class(pruned_tree)
pruned_tree <- train(
default ~ .,
data = train,
method = "rpart",
trControl = trainControl(method = "cv", number = 10),
tuneLength = 20
)
## Feature Interpretation
vip(pruned_tree, num_features = 16, bar = FALSE)
pruned_tree
plot(pruned_tree)
plotcp(pruned_tree)
printcp(pruned_tree)
pruned_tree <- train(
default ~ .,
data = train,
method = "rpart",
trControl = trainControl(method = "cv", number = 10),
tuneLength = 20
)
## Feature Interpretation
vip(pruned_tree, num_features = 16, bar = FALSE)
pred_default2 <- predict(pruned_tree, newdata=test, type="class")
pred_default2 <- predict(pruned_tree, newdata=test, type="raw")
caret::confusionMatrix(as.factor(test$default), pred_default2,
positive = "yes",dnn = c("Reference","Prediction"))
pred_default2_prob <- predict(pruned_tree, newdata=test, type="prob")
roc_tree2 <- roc(as.factor(test$default), pred_default2_prob[,"yes"])
plot(roc_tree2, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree2)))
pred_default2_prob <- predict(pruned_tree, newdata=test, type="prob")
roc_tree2 <- roc(as.factor(test$default), pred_default2_prob[,"yes"])
plot(roc_tree2, col="red", lwd=2)
title(main = paste('Area under the curve: ',auc(roc_tree2)))
